{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15c2148f-c1b0-46e0-87f6-2db29e13d5b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ENKI Visualize and Compare Plots\n",
    "\n",
    "[completed] Live demo of ENKI. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffa39c9-ca9b-4da0-90a4-de96bebbf755",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prepare\n",
    "Check environment. Install packages if in Colab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eae7403-f458-4f55-a557-4e045bd6f679",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" :((( \"\"\"\n",
    "from dataclasses import replace\n",
    "from datetime import datetime\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from urllib.parse import urlparse\n",
    "import datetime\n",
    "\n",
    "import argparse\n",
    "\n",
    "import healpy as hp\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Rectangle, Ellipse\n",
    "\n",
    "\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "\n",
    "mpl.rcParams['font.family'] = 'stixgeneral'\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import h5py\n",
    "\n",
    "from ulmo import plotting\n",
    "from ulmo.utils import utils as utils\n",
    "\n",
    "from ulmo import io as ulmo_io\n",
    "from ulmo.ssl import single_image as ssl_simage\n",
    "from ulmo.ssl import defs as ssl_defs\n",
    "from ulmo.mae import patch_analysis\n",
    "from ulmo.utils import image_utils\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import requests\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from ulmo.plotting import plotting\n",
    "\n",
    "# check whether run in Colab\n",
    "if 'google.colab' in sys.modules:\n",
    "    print('Running in Colab.')\n",
    "    !pip3 install timm==0.4.5  # 0.3.2 does not work in Colab\n",
    "    !git clone https://github.com/facebookresearch/mae.git\n",
    "    sys.path.append('./mae')\n",
    "else:\n",
    "    sys.path.append('..')\n",
    "import models_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7797ef-412a-439f-911e-3be294047629",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4573e6be-935a-4106-8c06-e467552b0e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the utils\n",
    "\n",
    "imagenet_mean = np.array([0.485, 0.456, 0.406])\n",
    "imagenet_std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "def show_image(image, title=''):\n",
    "    # image is [H, W, 3]\n",
    "    assert image.shape[2] == 1\n",
    "    _, cm = plotting.load_palette()\n",
    "    #plt.imshow(torch.clip((image * imagenet_std + imagenet_mean) * 255, 0, 255).int(), cmap=cm)\n",
    "    plt.imshow(image, cmap=cm)\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.axis('off')\n",
    "    return\n",
    "\n",
    "def prepare_model(chkpt_dir, arch='mae_vit_LLC_patch4'):\n",
    "    # build model\n",
    "    model = getattr(models_mae, arch)()\n",
    "    # load model\n",
    "    checkpoint = torch.load(chkpt_dir, map_location='cpu')\n",
    "    msg = model.load_state_dict(checkpoint['model'], strict=False)\n",
    "    print(msg)\n",
    "    return model\n",
    "\n",
    "def run_one_image(img, model, mask_ratio):\n",
    "    x = torch.tensor(img)\n",
    "\n",
    "    # make it a batch-like\n",
    "    x = x.unsqueeze(dim=0)\n",
    "    x = torch.einsum('nhwc->nchw', x)\n",
    "\n",
    "    # run MAE\n",
    "    loss, y, mask = model(x.float(), mask_ratio)\n",
    "    y = model.unpatchify(y)\n",
    "    y = torch.einsum('nchw->nhwc', y).detach().cpu()\n",
    "\n",
    "    # visualize the mask\n",
    "    mask = mask.detach()\n",
    "    mask = mask.unsqueeze(-1).repeat(1, 1, model.patch_embed.patch_size[0]**2 *1)  # (N, H*W, p*p*3)\n",
    "    mask = model.unpatchify(mask)  # 1 is removing, 0 is keeping\n",
    "    mask = torch.einsum('nchw->nhwc', mask).detach().cpu()\n",
    "    \n",
    "    x = torch.einsum('nchw->nhwc', x)\n",
    "\n",
    "    # masked image\n",
    "    im_masked = x * (1 - mask)\n",
    "\n",
    "    # MAE reconstruction pasted with visible patches\n",
    "    im_paste = x * (1 - mask) + y * mask\n",
    "    \n",
    "    im = im_paste.cpu().detach().numpy()\n",
    "    m = mask.cpu().detach().numpy()\n",
    "    im = im.squeeze()\n",
    "    m = m.squeeze()\n",
    "    \n",
    "    return im, m\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7e691d-93d2-439f-91d6-c22716a897b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load a pre-trained MAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c1c4ab-c301-40ff-a655-2bfca4c8cd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models:\n",
    "t10_file = 'data/ENKI_t10.pth'\n",
    "t35_file = 'data/ENKI_t35.pth'\n",
    "t50_file = 'data/ENKI_t50.pth'\n",
    "t75_file = 'data/ENKI_t75.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066c7a7b-a4b2-49f4-a113-a154347ae2ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load model trained on 10% masking\n",
    "model_mae_35 = prepare_model(t35_file, 'mae_vit_LLC_patch4')\n",
    "print('Model35 loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2d7da9-f75c-4b27-a84b-6d1247f73a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model trained on 10% masking\n",
    "model_mae_10 = prepare_model(t10_file, 'mae_vit_LLC_patch4')\n",
    "print('Model10 loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ab2395-521a-401f-a3d7-c0daead5c3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model trained on 50% masking\n",
    "model_mae_50 = prepare_model(t50_file, 'mae_vit_LLC_patch4')\n",
    "print('Model50 loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19da9fbf-07e3-4005-adb3-0f6e93470cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model trained on 75% masking\n",
    "model_mae_75 = prepare_model(t75_file, 'mae_vit_LLC_patch4')\n",
    "print('Model75 loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d15a0a7-c093-439a-9a4d-c37ce0c0eaa6",
   "metadata": {},
   "source": [
    "### Run MAE on the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0eb444-e403-44a9-a370-ff2326f78f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'data/MAE_LLC_valid_nonoise_preproc.h5'\n",
    "# seed = 1313\n",
    "# make random mask reproducible (comment out to make it change)\n",
    "group1 = [209248, 524321, 414040, 610138]\n",
    "group2 = [245215, 72480, 29518, 569580] \n",
    "group3 = [313043, 202716, 15385, 478432] \n",
    "group4 = [173629, 426310, 599472, 595621]\n",
    "\n",
    "\n",
    "indexes = [209248, 524321, 414040, 610138, 245215, 72480, 29518, 569580, \n",
    "           313043, 202716, 15385, 478432, 173629, 426310, 599472, 595621]\n",
    "f = h5py.File(filepath, 'r')\n",
    "\n",
    "models = [model_mae_10, model_mae_35, model_mae_50, model_mae_75]\n",
    "mask_ratios = [0.10, 0.35, 0.50, 0.75]\n",
    "\n",
    "orig_imgs = []\n",
    "recon_imgs = []\n",
    "masks = []\n",
    "\n",
    "for (idx, t, p) in zip(group1, models, mask_ratios):\n",
    "    orig_img = f['valid'][idx][0]\n",
    "    orig_img.resize((64,64,1))\n",
    "    recon_img, mask = run_one_image(orig_img, t, p)\n",
    "    orig_img = orig_img.squeeze()\n",
    "    orig_imgs.append(orig_img)\n",
    "    recon_imgs.append(recon_img)\n",
    "    masks.append(mask)\n",
    "    \n",
    "print(\"Group 1 finished.\")\n",
    "\n",
    "for (idx, t, p) in zip(group2, models, mask_ratios):\n",
    "    orig_img = f['valid'][idx][0]\n",
    "    orig_img.resize((64,64,1))\n",
    "    recon_img, mask = run_one_image(orig_img, t, p)\n",
    "    orig_img = orig_img.squeeze()\n",
    "    orig_imgs.append(orig_img)\n",
    "    recon_imgs.append(recon_img)\n",
    "    masks.append(mask)\n",
    "\n",
    "print(\"Group 2 finished.\")\n",
    "\n",
    "for (idx, t, p) in zip(group3, models, mask_ratios):\n",
    "    orig_img = f['valid'][idx][0]\n",
    "    orig_img.resize((64,64,1))\n",
    "    recon_img, mask = run_one_image(orig_img, t, p)\n",
    "    orig_img = orig_img.squeeze()\n",
    "    orig_imgs.append(orig_img)\n",
    "    recon_imgs.append(recon_img)\n",
    "    masks.append(mask)\n",
    "\n",
    "print(\"Group 3 finished.\")\n",
    "    \n",
    "for (idx, t, p) in zip(group4, models, mask_ratios):\n",
    "    orig_img = f['valid'][idx][0]\n",
    "    orig_img.resize((64,64,1))\n",
    "    recon_img, mask = run_one_image(orig_img, t, p)\n",
    "    orig_img = orig_img.squeeze()\n",
    "    orig_imgs.append(orig_img)\n",
    "    recon_imgs.append(recon_img)\n",
    "    masks.append(mask)\n",
    "\n",
    "print(\"Group 4 finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf5e5c4-2fbb-498c-a9af-e1b08341fb8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "orig_imgs = np.array(orig_imgs)\n",
    "recon_imgs = np.array(recon_imgs)\n",
    "masks = np.array(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9822ad6-1c8e-406e-872d-adcc2bc10143",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#masks = [p10_mask[0], p30_mask[0], p50_mask]\n",
    "np.savez('gallery_imgs.npz', orig_imgs=orig_imgs, recon_imgs=recon_imgs, masks=masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078a4949-008e-4c14-aaae-50324cf8bcca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
